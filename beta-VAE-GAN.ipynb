{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install biopython","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T12:40:35.236389Z","iopub.execute_input":"2026-02-10T12:40:35.23698Z","iopub.status.idle":"2026-02-10T12:40:38.428776Z","shell.execute_reply.started":"2026-02-10T12:40:35.236951Z","shell.execute_reply":"2026-02-10T12:40:38.427888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. Setup & Dependencies ---\n!pip install biopython\n\nimport os\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.utils.spectral_norm as spectral_norm\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.spatial.distance import pdist, squareform\nfrom skimage.metrics import structural_similarity as ssim\n\ntry:\n    from Bio.PDB import PDBList, PDBParser\nexcept ImportError:\n    print(\"Biopython not correctly installed. Please rerun the cell.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-10T12:49:26.82979Z","iopub.execute_input":"2026-02-10T12:49:26.830568Z","iopub.status.idle":"2026-02-10T12:49:29.973315Z","shell.execute_reply.started":"2026-02-10T12:49:26.830538Z","shell.execute_reply":"2026-02-10T12:49:29.972507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. Data Preparation ---\n\ndef fetch_pdb_ids(max_results=1000):\n    \"\"\"\n    Fetches a list of PDB IDs for protein structures from RCSB PDB API.\n    Filters: Protein only, Resolution < 3.0A, Length 50-500 residues.\n    \"\"\"\n    import requests\n    import json\n    \n    print(f\"Fetching list of up to {max_results} PDB IDs from RCSB...\")\n    \n    query = {\n        \"query\": {\n            \"type\": \"group\",\n            \"logical_operator\": \"and\",\n            \"nodes\": [\n                {\n                    \"type\": \"terminal\",\n                    \"service\": \"text\",\n                    \"parameters\": {\n                        \"attribute\": \"rcsb_entry_info.selected_polymer_entity_types\",\n                        \"operator\": \"exact_match\",\n                        \"value\": \"Protein (only)\"\n                    }\n                },\n                {\n                    \"type\": \"terminal\",\n                    \"service\": \"text\",\n                    \"parameters\": {\n                        \"attribute\": \"rcsb_entry_info.resolution_combined\",\n                        \"operator\": \"less\",\n                        \"value\": 3.0\n                    }\n                },\n                {\n                    \"type\": \"terminal\",\n                    \"service\": \"text\",\n                    \"parameters\": {\n                        \"attribute\": \"entity_poly.rcsb_sample_sequence_length\",\n                        \"operator\": \"range\",\n                        \"value\": {\"from\": 60, \"to\": 200} \n                    }\n                }\n            ]\n        },\n        \"request_options\": {\n            \"return_all_hits\": True\n        },\n        \"return_type\": \"entry\"\n    }\n    \n    url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n    try:\n        response = requests.post(url, json=query)\n        if response.status_code == 200:\n            data = response.json()\n            result_set = data.get(\"result_set\", [])\n            \n            # FIX: Extract 'identifier' if the API returns dictionaries\n            ids = []\n            for item in result_set:\n                if isinstance(item, dict):\n                    ids.append(item.get('identifier'))\n                else:\n                    ids.append(item)\n            \n            # Filter out any None values just in case\n            ids = [x for x in ids if x]\n            \n            print(f\"Found {len(ids)} potential structures.\")\n            return ids[:max_results]\n        else:\n            print(f\"Failed to query RCSB: {response.status_code}\")\n            return []\n    except Exception as e:\n        print(f\"Error checking RCSB: {e}\")\n        return ['1AIE', '1B7G', '1D0D', '6VSB'] # Fallback\n\ndef download_pdb_data(pdb_ids, download_dir=\"pdb_data\"):\n    \"\"\"Downloads PDB files.\"\"\"\n    os.makedirs(download_dir, exist_ok=True)\n    pdbl = PDBList()\n    \n    print(f\"Downloading {len(pdb_ids)} proteins to {download_dir}...\")\n    for i, pdb_id in enumerate(pdb_ids):\n        # Check if already exists (as .pdb or .ent)\n        final_path = os.path.join(download_dir, f\"{pdb_id}.pdb\")\n        ent_path_upper = os.path.join(download_dir, f\"{pdb_id}.ent\")\n        ent_path_lower = os.path.join(download_dir, f\"pdb{pdb_id.lower()}.ent\")\n        \n        if os.path.exists(final_path) or os.path.exists(ent_path_upper) or os.path.exists(ent_path_lower):\n            continue\n            \n        try:\n            pdbl.retrieve_pdb_file(pdb_id, pdir=download_dir, file_format=\"pdb\")\n            # Rename ent to pdb if possible, but keep .ent is fine if logic handles it\n            if os.path.exists(ent_path_lower):\n                os.rename(ent_path_lower, final_path)\n        except Exception:\n            continue\n            \n    print(\"Download complete.\")\n    # Debug: Check file count\n    files = os.listdir(download_dir)\n    print(f\"DEBUG: {len(files)} files found in {download_dir}. First 5: {files[:5]}\")\n\ndef get_ca_coordinates(pdb_file):\n    \"\"\"Extracts Alpha-Carbon coordinates.\"\"\"\n    parser = PDBParser(QUIET=True)\n    try:\n        structure = parser.get_structure('protein', pdb_file)\n    except Exception:\n        return np.array([])\n        \n    ca_coords = []\n    for model in structure:\n        for chain in model:\n            for residue in chain:\n                if 'CA' in residue:\n                    ca_coords.append(residue['CA'].get_coord())\n        break \n    return np.array(ca_coords)\n\ndef get_contact_map(coords, threshold=8.0, size=64):\n    \"\"\"Generates a binary contact map from coordinates.\"\"\"\n    if len(coords) < 10: return torch.zeros((1, size, size))\n    \n    dist_matrix = squareform(pdist(coords))\n    contact_map = (dist_matrix < threshold).astype(float)\n    \n    result = np.zeros((size, size))\n    m, n = contact_map.shape[:2]\n    h, w = min(m, size), min(n, size)\n    result[:h, :w] = contact_map[:h, :w]\n    \n    return torch.tensor(result, dtype=torch.float32).unsqueeze(0)\n\nclass PDBContactMapDataset(Dataset):\n    def __init__(self, pdb_dir, size=64):\n        # Support both .pdb and .ent (common download format)\n        self.pdb_files = [\n            os.path.join(pdb_dir, f) for f in os.listdir(pdb_dir) \n            if f.endswith('.pdb') or f.endswith('.ent')\n        ]\n        self.size = size\n        \n    def __len__(self):\n        return len(self.pdb_files)\n        \n    def __getitem__(self, idx):\n        try:\n            coords = get_ca_coordinates(self.pdb_files[idx])\n            return get_contact_map(coords, size=self.size)\n        except Exception:\n            return torch.zeros((1, self.size, self.size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:17:20.162606Z","iopub.execute_input":"2026-02-10T13:17:20.162957Z","iopub.status.idle":"2026-02-10T13:17:20.179642Z","shell.execute_reply.started":"2026-02-10T13:17:20.162931Z","shell.execute_reply":"2026-02-10T13:17:20.17883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 3. High-Capacity Model Architectures ---\n\nclass ResNetBlock(nn.Module):\n    def __init__(self, channels):\n        super(ResNetBlock, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(channels, channels, 3, 1, 1),\n            nn.BatchNorm2d(channels),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(channels, channels, 3, 1, 1),\n            nn.BatchNorm2d(channels)\n        )\n    def forward(self, x):\n        return x + self.conv(x)\n\nclass ResNetVAE(nn.Module):\n    def __init__(self, latent_dim=512):\n        super(ResNetVAE, self).__init__()\n        \n        # Encoder: Deep and Wide\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 64, 4, 2, 1), # 32x32\n            nn.LeakyReLU(0.2),\n            \n            nn.Conv2d(64, 128, 4, 2, 1), # 16x16\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n            ResNetBlock(128),\n            \n            nn.Conv2d(128, 256, 4, 2, 1), # 8x8\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2),\n            ResNetBlock(256),\n            \n            nn.Conv2d(256, 512, 4, 2, 1), # 4x4\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n            ResNetBlock(512),\n            \n            nn.Conv2d(512, 1024, 4, 1, 0), # 1x1\n            nn.Flatten()\n        )\n        \n        self.fc_mu = nn.Linear(1024, latent_dim)\n        self.fc_logvar = nn.Linear(1024, latent_dim)\n        \n        # Decoder\n        self.decoder_input = nn.Linear(latent_dim, 1024)\n        self.decoder = nn.Sequential(\n            nn.Unflatten(1, (1024, 1, 1)),\n            nn.ConvTranspose2d(1024, 512, 4, 1, 0), # 4x4\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n            ResNetBlock(512),\n            \n            nn.ConvTranspose2d(512, 256, 4, 2, 1), # 8x8\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2),\n            \n            nn.ConvTranspose2d(256, 128, 4, 2, 1), # 16x16\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n            \n            nn.ConvTranspose2d(128, 64, 4, 2, 1), # 32x32\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.2),\n            \n            nn.ConvTranspose2d(64, 1, 4, 2, 1), # 64x64\n            nn.Sigmoid()\n        )\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        mu, logvar = self.fc_mu(encoded), self.fc_logvar(encoded)\n        z = self.reparameterize(mu, logvar)\n        return self.decoder(self.decoder_input(z)), mu, logvar\n\nclass DeepDiscriminator(nn.Module):\n    def __init__(self):\n        super(DeepDiscriminator, self).__init__()\n        \n        def sn_conv(in_c, out_c):\n            return spectral_norm(nn.Conv2d(in_c, out_c, 4, 2, 1))\n\n        self.model = nn.Sequential(\n            sn_conv(1, 64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            sn_conv(64, 128),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            sn_conv(128, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            sn_conv(256, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            sn_conv(512, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Flatten(),\n            nn.Linear(1024 * 2 * 2, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:17:23.571787Z","iopub.execute_input":"2026-02-10T13:17:23.572336Z","iopub.status.idle":"2026-02-10T13:17:23.584782Z","shell.execute_reply.started":"2026-02-10T13:17:23.572307Z","shell.execute_reply":"2026-02-10T13:17:23.584035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 4. Training Functions ---\n\ndef calculate_metrics(real_batch, recon_batch):\n    real = real_batch.detach().cpu().numpy().squeeze()\n    recon = recon_batch.detach().cpu().numpy().squeeze()\n    scores = []\n    if len(real.shape) == 2:\n        return ssim(real, recon, data_range=1.0)\n    for i in range(len(real)):\n        scores.append(ssim(real[i], recon[i], data_range=1.0))\n    return np.mean(scores)\n\ndef train_vae_phase(vae, loader, epochs=50, device='cuda'):\n    print(\"\\n[Phase 1] Training VAE...\")\n    optimizer = optim.Adam(vae.parameters(), lr=1e-4)\n    vae.to(device)\n    vae.train()\n    \n    for epoch in range(epochs):\n        epoch_loss = 0\n        total_ssim = 0\n        for batch in loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            \n            recon, mu, logvar = vae(batch)\n            bce = nn.functional.binary_cross_entropy(recon, batch, reduction='sum')\n            kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n            loss = bce + kld\n            \n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            if np.random.rand() < 0.1:\n                total_ssim += calculate_metrics(batch, recon)\n            \n        print(f\"Epoch {epoch+1}/{epochs} - VAE Loss: {epoch_loss/len(loader.dataset):.2f}\")\n    return vae\n\ndef train_gan_phase(generator, discriminator, loader, epochs=50, device='cuda', latent_dim=512):\n    print(\"\\n[Phase 2] Training Pure GAN...\")\n    generator.to(device); discriminator.to(device)\n    opt_g = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n    opt_d = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n    criterion = nn.BCELoss()\n    \n    for epoch in range(epochs):\n        for batch in loader:\n            batch = batch.to(device)\n            b_size = batch.size(0)\n            \n            # Train Disc\n            opt_d.zero_grad()\n            real_labels = torch.ones(b_size, 1).to(device)\n            fake_labels = torch.zeros(b_size, 1).to(device)\n            \n            d_real_loss = criterion(discriminator(batch), real_labels)\n            \n            z = torch.randn(b_size, latent_dim).to(device)\n            # Use VAE decoder part as generic generator input\n            # If data parallel, access module\n            if isinstance(generator, nn.DataParallel):\n                fake_imgs = generator.module.decoder(generator.module.decoder_input(z))\n            else:\n                fake_imgs = generator.decoder(generator.decoder_input(z))\n            \n            d_fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n            d_loss = d_real_loss + d_fake_loss\n            d_loss.backward()\n            opt_d.step()\n            \n            # Train Gen\n            opt_g.zero_grad()\n            g_loss = criterion(discriminator(fake_imgs), real_labels)\n            g_loss.backward()\n            opt_g.step()\n        \n        print(f\"Epoch {epoch+1}/{epochs} - D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n\ndef train_vaegan_phase(vae, discriminator, loader, epochs=100, device='cuda', gamma=20.0):\n    print(\"\\n[Phase 3] Training VAE-GAN...\")\n    vae.to(device); discriminator.to(device)\n    \n    opt_vae = optim.Adam(vae.parameters(), lr=1e-4)\n    opt_disc = optim.Adam(discriminator.parameters(), lr=1e-5)\n    criterion = nn.BCELoss()\n    \n    for epoch in range(epochs):\n        for batch in loader:\n            real_imgs = batch.to(device)\n            b_size = real_imgs.size(0)\n            \n            # --- Train Discriminator ---\n            opt_disc.zero_grad()\n            valid = torch.ones(b_size, 1).to(device)\n            fake = torch.zeros(b_size, 1).to(device)\n            \n            d_real_loss = criterion(discriminator(real_imgs), valid)\n            \n            recon, _, _ = vae(real_imgs)\n            d_recon_loss = criterion(discriminator(recon.detach()), fake)\n            \n            z = torch.randn(b_size, 512).to(device)\n            if isinstance(vae, nn.DataParallel):\n                gen_imgs = vae.module.decoder(vae.module.decoder_input(z))\n            else:\n                gen_imgs = vae.decoder(vae.decoder_input(z))\n                \n            d_gen_loss = criterion(discriminator(gen_imgs.detach()), fake)\n            \n            d_loss = d_real_loss + 0.5 * (d_recon_loss + d_gen_loss)\n            d_loss.backward()\n            opt_disc.step()\n            \n            # --- Train VAE ---\n            opt_vae.zero_grad()\n            \n            recon, mu, logvar = vae(real_imgs)\n            bce = nn.functional.binary_cross_entropy(recon, real_imgs, reduction='sum')\n            kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n            \n            g_adv_loss = criterion(discriminator(recon), valid)\n            \n            vae_loss = bce + kld + (gamma * g_adv_loss)\n            vae_loss.backward()\n            opt_vae.step()\n\n        print(f\"Epoch {epoch+1}/{epochs} - VAE Loss: {vae_loss.item():.2f} | D Loss: {d_loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:17:26.817111Z","iopub.execute_input":"2026-02-10T13:17:26.817408Z","iopub.status.idle":"2026-02-10T13:17:26.833778Z","shell.execute_reply.started":"2026-02-10T13:17:26.817385Z","shell.execute_reply":"2026-02-10T13:17:26.832914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 5. Initialization & Setup ---\n\n# Configuration\nBATCH_SIZE = 32 # Suitable for 25GB VRAM (2x T4)\nLATENT_DIM = 512\n\n# Fetch Data\npdb_ids = fetch_pdb_ids(max_results=500)\nif not pdb_ids: pdb_ids = ['1AIE', '1B7G', '1D0D', '6VSB']\ndownload_pdb_data(pdb_ids)\n\n# Create Loader\ndataset = PDBContactMapDataset(\"pdb_data\")\ntrain_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nprint(f\"Dataset loaded: {len(dataset)} proteins.\")\n\n# Initialize Models & Hardware\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvae = ResNetVAE(latent_dim=LATENT_DIM)\ndisc = DeepDiscriminator()\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    vae = nn.DataParallel(vae)\n    disc = nn.DataParallel(disc)\n\nvae.to(device)\ndisc.to(device)\nprint(\"Models initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:17:31.101039Z","iopub.execute_input":"2026-02-10T13:17:31.101317Z","iopub.status.idle":"2026-02-10T13:19:05.466702Z","shell.execute_reply.started":"2026-02-10T13:17:31.101291Z","shell.execute_reply":"2026-02-10T13:19:05.465872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_model(vae, discriminator=None, phase_name=\"checkpoint\", save_dir=\"checkpoints\"):\n    \"\"\"\n    Saves model weights to disk. \n    Handles DataParallel wrappers automatically.\n    \"\"\"\n    import os\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # Save VAE\n    if vae:\n        # standardizing to single GPU state dict\n        vae_state = vae.module.state_dict() if isinstance(vae, nn.DataParallel) else vae.state_dict()\n        torch.save(vae_state, os.path.join(save_dir, f\"vae_{phase_name}.pth\"))\n        \n    # Save Discriminator\n    if discriminator:\n        disc_state = discriminator.module.state_dict() if isinstance(discriminator, nn.DataParallel) else discriminator.state_dict()\n        torch.save(disc_state, os.path.join(save_dir, f\"disc_{phase_name}.pth\"))\n        \n    print(f\"Saved models for '{phase_name}' to {save_dir}/\")\ndef load_model(vae, discriminator=None, phase_name=\"checkpoint\", save_dir=\"checkpoints\", device='cuda'):\n    \"\"\"\n    Loads model weights from disk.\n    Safe to use even if models are wrapped in DataParallel.\n    \"\"\"\n    import os\n    vae_path = os.path.join(save_dir, f\"vae_{phase_name}.pth\")\n    disc_path = os.path.join(save_dir, f\"disc_{phase_name}.pth\")\n    \n    # Load VAE\n    if vae and os.path.exists(vae_path):\n        # map_location ensures we can load CUDA models on CPU if needed (or vice versa)\n        state_dict = torch.load(vae_path, map_location=device)\n        if isinstance(vae, nn.DataParallel):\n            vae.module.load_state_dict(state_dict)\n        else:\n            vae.load_state_dict(state_dict)\n        print(f\"Loaded VAE from {vae_path}\")\n    elif vae:\n        print(f\"Warning: VAE checkpoint not found at {vae_path}\")\n        \n    # Load Discriminator\n    if discriminator and os.path.exists(disc_path):\n        state_dict = torch.load(disc_path, map_location=device)\n        if isinstance(discriminator, nn.DataParallel):\n            discriminator.module.load_state_dict(state_dict)\n        else:\n            discriminator.load_state_dict(state_dict)\n        print(f\"Loaded Discriminator from {disc_path}\")\n    elif discriminator:\n        print(f\"Warning: Discriminator checkpoint not found at {disc_path}\")\n    \n    # Ensure on device\n    if vae: vae.to(device)\n    if discriminator: discriminator.to(device)\nprint(\"Checkpoint utilities initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:37:32.964125Z","iopub.execute_input":"2026-02-10T13:37:32.96482Z","iopub.status.idle":"2026-02-10T13:37:32.973913Z","shell.execute_reply.started":"2026-02-10T13:37:32.964789Z","shell.execute_reply":"2026-02-10T13:37:32.973207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Visualization Functions ---\n\ndef visualize_results(model, loader, device='cuda', num_samples=5, title=\"Model Results\"):\n    \"\"\"\n    Visualizes:\n    1. Real Contact Maps (from the dataset)\n    2. Reconstructed Maps (what the VAE thinks the input is)\n    3. Generated Maps (random proteins from latent space)\n    \"\"\"\n    model.eval()\n    \n    # 1. Get Real Images\n    data = next(iter(loader))\n    real_imgs = data[:num_samples].to(device)\n    \n    with torch.no_grad():\n        # 2. Get Reconstructions (only valid for VAE/VAE-GAN phases)\n        try:\n            recon_imgs, _, _ = model(real_imgs)\n            show_recon = True\n        except:\n            # If the model is in pure GAN mode or doesn't return tuple\n            show_recon = False\n\n        # 3. Generate New Samples (Latent Walk)\n        z = torch.randn(num_samples, 512).to(device)\n        \n        # Handle DataParallel (if using multiple GPUs)\n        if isinstance(model, nn.DataParallel):\n            inner_gen = model.module\n        else:\n            inner_gen = model\n            \n        # Manually decode from latent Z\n        gen_imgs = inner_gen.decoder(inner_gen.decoder_input(z))\n    \n    # Move to CPU for plotting\n    real_imgs = real_imgs.cpu().numpy().squeeze()\n    gen_imgs = gen_imgs.cpu().numpy().squeeze()\n    if show_recon:\n        recon_imgs = recon_imgs.cpu().numpy().squeeze()\n        \n    # Plotting\n    rows = 3 if show_recon else 2\n    fig, axes = plt.subplots(rows, num_samples, figsize=(num_samples * 3, rows * 3))\n    plt.suptitle(title, fontsize=16)\n    \n    for i in range(num_samples):\n        # Plot Real\n        ax_real = axes[0, i] if rows > 1 else axes[i]\n        ax_real.imshow(real_imgs[i], cmap='viridis', origin='lower')\n        if i == 0: ax_real.set_ylabel(\"Real\", fontsize=14, fontweight='bold')\n        ax_real.axis('off')\n        \n        # Plot Reconstruction\n        if show_recon:\n            ax_recon = axes[1, i]\n            ax_recon.imshow(recon_imgs[i], cmap='viridis', origin='lower')\n            if i == 0: ax_recon.set_ylabel(\"Reconstructed\", fontsize=14, fontweight='bold')\n            ax_recon.axis('off')\n            \n        # Plot Generated\n        row_idx = 2 if show_recon else 1\n        ax_gen = axes[row_idx, i] if rows > 1 else axes[i]\n        ax_gen.imshow(gen_imgs[i], cmap='viridis', origin='lower')\n        if i == 0: ax_gen.set_ylabel(\"Generated\", fontsize=14, fontweight='bold')\n        ax_gen.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n    model.train() # Switch back to train mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:38:22.281933Z","iopub.execute_input":"2026-02-10T13:38:22.282619Z","iopub.status.idle":"2026-02-10T13:38:22.291501Z","shell.execute_reply.started":"2026-02-10T13:38:22.282588Z","shell.execute_reply":"2026-02-10T13:38:22.290779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_vae_phase(vae, train_loader, epochs=50, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:20:34.059577Z","iopub.execute_input":"2026-02-10T13:20:34.060236Z","iopub.status.idle":"2026-02-10T13:36:52.36823Z","shell.execute_reply.started":"2026-02-10T13:20:34.060204Z","shell.execute_reply":"2026-02-10T13:36:52.367641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_model(vae, discriminator=None, phase_name=\"phase1_vae\")\nvisualize_results(vae, train_loader, device=device, title=\"Result: Phase 1 (VAE)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:38:38.253415Z","iopub.execute_input":"2026-02-10T13:38:38.254164Z","iopub.status.idle":"2026-02-10T13:38:40.001289Z","shell.execute_reply.started":"2026-02-10T13:38:38.254133Z","shell.execute_reply":"2026-02-10T13:38:40.000588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_gan_phase(vae, disc, train_loader, epochs=50, device=device, latent_dim=LATENT_DIM)\nsave_model(vae, disc, \"phase2_gan\")\nvisualize_results(vae, train_loader, device=device, title=\"Result: Phase 2 (GAN)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T13:40:08.603744Z","iopub.execute_input":"2026-02-10T13:40:08.604565Z","iopub.status.idle":"2026-02-10T13:55:57.177316Z","shell.execute_reply.started":"2026-02-10T13:40:08.604531Z","shell.execute_reply":"2026-02-10T13:55:57.176769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 8. Execution: Phase 3 (VAE-GAN Training) ---\n# Uncomment to run\ntrain_vaegan_phase(vae, disc, train_loader, epochs=100, device=device, gamma=20.0)\nsave_model(vae, disc, \"phase3_vaegan\")\nvisualize_results(vae, train_loader, device=device, title=\"Result: Phase 3 (VAE-GAN)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:08:38.688559Z","iopub.execute_input":"2026-02-10T14:08:38.689367Z","iopub.status.idle":"2026-02-10T14:41:48.437793Z","shell.execute_reply.started":"2026-02-10T14:08:38.689338Z","shell.execute_reply":"2026-02-10T14:41:48.437073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"hello\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:59:44.376678Z","iopub.execute_input":"2026-02-10T14:59:44.377411Z","iopub.status.idle":"2026-02-10T14:59:44.381303Z","shell.execute_reply.started":"2026-02-10T14:59:44.377381Z","shell.execute_reply":"2026-02-10T14:59:44.380675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}