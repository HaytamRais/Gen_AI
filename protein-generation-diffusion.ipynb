{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Protein Structure Generation with Diffusion Models (DDPM)\n\nThis notebook implements a **Denoising Diffusion Probabilistic Model (DDPM)** to generate protein contact maps.\n\n**Key Components**:\n1.  **Robust Data Pipeline**: Uses the same PDB fetching and contact map generation as our VAE-GAN work.\n2.  **U-Net Architecture**: A deep residual U-Net with time embeddings to predict noise at each timestep.\n3.  **Diffusion Process**: Forward process (adding noise) and Reverse process (learning to denoiose).\n\n**Hardware**: Optimized for **25GB+ VRAM** (e.g., 2x T4 GPUs in Colab).","metadata":{}},{"cell_type":"code","source":"# --- 1. Setup & Dependencies ---\n!pip install biopython\n\nimport os\nimport time\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.spatial.distance import pdist, squareform\n\ntry:\n    from Bio.PDB import PDBList, PDBParser\nexcept ImportError:\n    print(\"Biopython not correctly installed. Please rerun the cell.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:35:20.701095Z","iopub.execute_input":"2026-02-10T14:35:20.701424Z","iopub.status.idle":"2026-02-10T14:35:23.704729Z","shell.execute_reply.started":"2026-02-10T14:35:20.70138Z","shell.execute_reply":"2026-02-10T14:35:23.704057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. Data Preparation (Identical to VAE-GAN) ---\n\ndef fetch_pdb_ids(max_results=1000):\n    \"\"\"\n    Fetches a list of PDB IDs for protein structures from RCSB PDB API.\n    Filters: Protein only, Resolution < 3.0A, Length 50-500 residues.\n    \"\"\"\n    import requests\n    import json\n    \n    print(f\"Fetching list of up to {max_results} PDB IDs from RCSB...\")\n    \n    query = {\n        \"query\": {\n            \"type\": \"group\",\n            \"logical_operator\": \"and\",\n            \"nodes\": [\n                {\n                    \"type\": \"terminal\",\n                    \"service\": \"text\",\n                    \"parameters\": {\n                        \"attribute\": \"rcsb_entry_info.selected_polymer_entity_types\",\n                        \"operator\": \"exact_match\",\n                        \"value\": \"Protein (only)\"\n                    }\n                },\n                {\n                    \"type\": \"terminal\",\n                    \"service\": \"text\",\n                    \"parameters\": {\n                        \"attribute\": \"rcsb_entry_info.resolution_combined\",\n                        \"operator\": \"less\",\n                        \"value\": 3.0\n                    }\n                },\n                {\n                    \"type\": \"terminal\",\n                    \"service\": \"text\",\n                    \"parameters\": {\n                        \"attribute\": \"entity_poly.rcsb_sample_sequence_length\",\n                        \"operator\": \"range\",\n                        \"value\": {\"from\": 60, \"to\": 200} \n                    }\n                }\n            ]\n        },\n        \"request_options\": {\n            \"return_all_hits\": True\n        },\n        \"return_type\": \"entry\"\n    }\n    \n    url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n    try:\n        response = requests.post(url, json=query)\n        if response.status_code == 200:\n            data = response.json()\n            # Extract identifiers from the result set\n            result_set = data.get(\"result_set\", [])\n            ids = []\n            for item in result_set:\n                if isinstance(item, dict) and 'identifier' in item:\n                    ids.append(item['identifier'])\n                elif isinstance(item, str):\n                    ids.append(item)\n            \n            print(f\"Found {len(ids)} potential structures.\")\n            return ids[:max_results]\n        else:\n            print(f\"Failed to query RCSB: {response.status_code}\")\n            return []\n    except Exception as e:\n        print(f\"Error checking RCSB: {e}\")\n        return ['1AIE', '1B7G', '1D0D', '6VSB'] # Fallback\n\ndef download_pdb_data(pdb_ids, download_dir=\"pdb_data\"):\n    \"\"\"Downloads PDB files.\"\"\"\n    os.makedirs(download_dir, exist_ok=True)\n    pdbl = PDBList()\n    \n    print(f\"Downloading {len(pdb_ids)} proteins to {download_dir}...\")\n    for i, pdb_id in enumerate(pdb_ids):\n        final_path = os.path.join(download_dir, f\"{pdb_id}.pdb\")\n        ent_path_upper = os.path.join(download_dir, f\"{pdb_id}.ent\")\n        ent_path_lower = os.path.join(download_dir, f\"pdb{pdb_id.lower()}.ent\")\n        \n        if os.path.exists(final_path) or os.path.exists(ent_path_upper) or os.path.exists(ent_path_lower):\n            continue\n            \n        try:\n            pdbl.retrieve_pdb_file(pdb_id, pdir=download_dir, file_format=\"pdb\")\n            if os.path.exists(ent_path_lower):\n                os.rename(ent_path_lower, final_path)\n        except Exception:\n            continue\n            \n    print(\"Download complete.\")\n\ndef get_ca_coordinates(pdb_file):\n    \"\"\"Extracts Alpha-Carbon coordinates.\"\"\"\n    parser = PDBParser(QUIET=True)\n    try:\n        structure = parser.get_structure('protein', pdb_file)\n    except Exception:\n        return np.array([])\n        \n    ca_coords = []\n    for model in structure:\n        for chain in model:\n            for residue in chain:\n                if 'CA' in residue:\n                    ca_coords.append(residue['CA'].get_coord())\n        break \n    return np.array(ca_coords)\n\ndef get_contact_map(coords, threshold=8.0, size=64):\n    \"\"\"Generates a binary contact map from coordinates.\"\"\"\n    if len(coords) < 10: return torch.zeros((1, size, size))\n    \n    dist_matrix = squareform(pdist(coords))\n    contact_map = (dist_matrix < threshold).astype(float)\n    \n    # IMPORTANT: Diffusion models work best with input in range [-1, 1]\n    # Standard contact map is [0, 1]. We will scale it later or during dataset getitem.\n    # For simplicity, let's keep it [0, 1] here and Normalize in transform if needed.\n    \n    result = np.zeros((size, size))\n    m, n = contact_map.shape[:2]\n    h, w = min(m, size), min(n, size)\n    result[:h, :w] = contact_map[:h, :w]\n    \n    return torch.tensor(result, dtype=torch.float32).unsqueeze(0)\n\nclass PDBContactMapDataset(Dataset):\n    def __init__(self, pdb_dir, size=64):\n        self.pdb_files = [\n            os.path.join(pdb_dir, f) for f in os.listdir(pdb_dir) \n            if f.endswith('.pdb') or f.endswith('.ent')\n        ]\n        self.size = size\n        \n    def __len__(self):\n        return len(self.pdb_files)\n        \n    def __getitem__(self, idx):\n        try:\n            coords = get_ca_coordinates(self.pdb_files[idx])\n            t = get_contact_map(coords, size=self.size)\n            # Scale to [-1, 1] for Diffusion\n            return t * 2.0 - 1.0 \n        except Exception:\n            return torch.zeros((1, self.size, self.size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:35:23.706507Z","iopub.execute_input":"2026-02-10T14:35:23.706988Z","iopub.status.idle":"2026-02-10T14:35:23.723862Z","shell.execute_reply.started":"2026-02-10T14:35:23.706959Z","shell.execute_reply":"2026-02-10T14:35:23.723152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 3. Diffusion Model Architecture (U-Net) ---\n# Based on standard DDPM implementations\n\nclass SinusoidalPositionEmbeddings(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, time):\n        device = time.device\n        half_dim = self.dim // 2\n        embeddings = math.log(10000) / (half_dim - 1)\n        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n        embeddings = time[:, None] * embeddings[None, :]\n        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n        return embeddings\n\nclass Block(nn.Module):\n    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n        super().__init__()\n        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n        if up:\n            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n        else:\n            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n        self.bnorm1 = nn.BatchNorm2d(out_ch)\n        self.bnorm2 = nn.BatchNorm2d(out_ch)\n        self.relu  = nn.ReLU()\n\n    def forward(self, x, t):\n        # First Conv\n        h = self.bnorm1(self.relu(self.conv1(x)))\n        # Time Embedding\n        time_emb = self.relu(self.time_mlp(t))\n        # Extend last 2 dimensions\n        time_emb = time_emb[(..., ) + (None, ) * 2]\n        # Add time channel\n        h = h + time_emb\n        # Second Conv\n        h = self.bnorm2(self.relu(self.conv2(h)))\n        # Down or Upsample\n        return self.transform(h)\n\nclass SimpleUnet(nn.Module):\n    \"\"\"\n    A simplified U-Net architecture for Diffusion.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        image_channels = 1\n        down_channels = (64, 128, 256, 512, 1024)\n        up_channels = (1024, 512, 256, 128, 64)\n        out_dim = 1 \n        time_emb_dim = 32\n\n        # Time embedding\n        self.time_mlp = nn.Sequential(\n            SinusoidalPositionEmbeddings(time_emb_dim),\n            nn.Linear(time_emb_dim, time_emb_dim),\n            nn.ReLU()\n        )\n        \n        # Initial projection\n        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)\n\n        # Downsample\n        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], time_emb_dim) for i in range(len(down_channels)-1)])\n        \n        # Upsample\n        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], time_emb_dim, up=True) for i in range(len(up_channels)-1)])\n        \n        self.output = nn.Conv2d(up_channels[-1], out_dim, 1)\n\n    def forward(self, x, timestep):\n        # Embed time\n        t = self.time_mlp(timestep)\n        # Initial conv\n        x = self.conv0(x)\n        # Residual connections\n        residuals = []\n        for down in self.downs:\n            x = down(x, t)\n            residuals.append(x)\n        for up in self.ups:\n            residual = residuals.pop()\n            # Concatenate\n            x = torch.cat((x, residual), dim=1)\n            x = up(x, t)\n        return self.output(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:35:27.397066Z","iopub.execute_input":"2026-02-10T14:35:27.397573Z","iopub.status.idle":"2026-02-10T14:35:27.409378Z","shell.execute_reply.started":"2026-02-10T14:35:27.397543Z","shell.execute_reply":"2026-02-10T14:35:27.408563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 4. Models & Diffusion Logic ---\n\n# Hyperparameters\nT = 300 # Timesteps (keep low for speed in dry run)\nbeta_start = 0.0001\nbeta_end = 0.02\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define Beta Schedule (Linear)\nbetas = torch.linspace(beta_start, beta_end, T).to(device)\nalphas = 1. - betas\nalphas_cumprod = torch.cumprod(alphas, axis=0)\nalphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\nsqrt_recip_alphas = torch.sqrt(1.0 / alphas)\nsqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\nsqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\nposterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n\ndef forward_diffusion_sample(x_0, t, device=\"cuda\"):\n    \"\"\" \n    Takes an image and a timestep t and returns the noisy version of it at t\n    \"\"\"\n    noise = torch.randn_like(x_0)\n    sqrt_alphas_cumprod_t = sqrt_alphas_cumprod[t][:, None, None, None]\n    sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n    \n    # Reparameterization trick: mean + std * noise\n    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise, noise\n\n@torch.no_grad()\ndef sample_plot_image(model, img_size=64, device=\"cuda\"):\n    # Sample noise\n    img = torch.randn((1, 1, img_size, img_size), device=device)\n    model.eval()\n    \n    for i in range(0, T)[::-1]:\n        t = torch.full((1,), i, device=device, dtype=torch.long)\n        img_pred_noise = model(img, t)\n        \n        # Sampling algo\n        alpha = alphas[i]\n        alpha_hat = alphas_cumprod[i]\n        beta = betas[i]\n        if i > 1:\n            noise = torch.randn_like(img)\n        else:\n            noise = torch.zeros_like(img)\n            \n        img = 1 / torch.sqrt(alpha) * (img - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * img_pred_noise) + torch.sqrt(beta) * noise\n        \n    model.train()\n    # Clip to -1, 1\n    img = torch.clamp(img, -1.0, 1.0)\n    # Convert to 0, 1 for plot\n    img = (img + 1) / 2\n    \n    plt.imshow(img.cpu().squeeze().numpy(), cmap='binary')\n    plt.title(\"Generated Protein Contact Map\")\n    plt.show()\n\ndef get_loss(model, x_0, t):\n    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n    noise_pred = model(x_noisy, t)\n    return F.l1_loss(noise, noise_pred) # L1 loss is often better for diffusion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:35:32.480102Z","iopub.execute_input":"2026-02-10T14:35:32.480391Z","iopub.status.idle":"2026-02-10T14:35:32.491896Z","shell.execute_reply.started":"2026-02-10T14:35:32.480365Z","shell.execute_reply":"2026-02-10T14:35:32.491179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 5. Training Loop ---\n\ndef train_diffusion(model, loader, epochs=100):\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    model.to(device)\n    \n    for epoch in range(epochs):\n        epoch_loss = 0\n        for batch in loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            \n            # Sample random timesteps\n            t = torch.randint(0, T, (batch.shape[0],), device=device).long()\n            \n            loss = get_loss(model, batch, t)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        \n        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(loader):.4f}\")\n        if (epoch + 1) % 10 == 0:\n            sample_plot_image(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:35:38.623965Z","iopub.execute_input":"2026-02-10T14:35:38.624587Z","iopub.status.idle":"2026-02-10T14:35:38.629851Z","shell.execute_reply.started":"2026-02-10T14:35:38.624557Z","shell.execute_reply":"2026-02-10T14:35:38.629142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 6. Execution ---\n\n# 1. Fetch & Download Data\npdb_ids = fetch_pdb_ids(max_results=1000)\nif not pdb_ids: \n    pdb_ids = ['1AIE', '1B7G', '1D0D', '6VSB']\ndownload_pdb_data(pdb_ids)\n\n# 2. Loader\nBATCH_SIZE = 32\ndataset = PDBContactMapDataset(\"pdb_data\")\nloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nprint(f\"Loaded {len(dataset)} items.\")\n\n# 3. Model\nmodel = SimpleUnet()\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\nmodel.to(device)\n\n# 4. Train\n# Uncomment to start training\n# train_diffusion(model, loader, epochs=200)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:35:49.064216Z","iopub.execute_input":"2026-02-10T14:35:49.064593Z","iopub.status.idle":"2026-02-10T14:38:45.853117Z","shell.execute_reply.started":"2026-02-10T14:35:49.064566Z","shell.execute_reply":"2026-02-10T14:38:45.852353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_diffusion(model, loader, epochs=200)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T14:39:37.788656Z","iopub.execute_input":"2026-02-10T14:39:37.788975Z","iopub.status.idle":"2026-02-10T17:09:19.545657Z","shell.execute_reply.started":"2026-02-10T14:39:37.788949Z","shell.execute_reply":"2026-02-10T17:09:19.544811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 7. Evaluation, Visualization & Storage ---\n\n# 1. Save the Model\nprint(\"Saving model to 'ddpm_protein_model.pth'...\")\nif isinstance(model, nn.DataParallel):\n    torch.save(model.module.state_dict(), \"ddpm_protein_model.pth\")\nelse:\n    torch.save(model.state_dict(), \"ddpm_protein_model.pth\")\nprint(\"Model saved successfully.\")\n\n# 2. Evaluation Helper Function\n@torch.no_grad()\ndef generate_and_compare(model, dataset, num_samples=5, device=\"cuda\"):\n    model.eval()\n    \n    # --- A. Get Real Samples ---\n    real_samples = []\n    idxs = np.random.choice(len(dataset), num_samples, replace=False)\n    for i in idxs:\n        real_samples.append(dataset[i])\n    real_samples = torch.stack(real_samples).to(device)\n    \n    # --- B. Generate Fake Samples (Reverse Diffusion) ---\n    print(f\"Generating {num_samples} samples from noise...\")\n    # Start from pure noise\n    img = torch.randn((num_samples, 1, 64, 64), device=device)\n    \n    # Iteratively denoise\n    for i in range(0, T)[::-1]:\n        t = torch.full((num_samples,), i, device=device, dtype=torch.long)\n        img_pred_noise = model(img, t)\n        \n        alpha = alphas[i]\n        alpha_hat = alphas_cumprod[i]\n        beta = betas[i]\n        \n        if i > 1:\n            noise = torch.randn_like(img)\n        else:\n            noise = torch.zeros_like(img)\n            \n        img = 1 / torch.sqrt(alpha) * (img - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * img_pred_noise) + torch.sqrt(beta) * noise\n        \n    # Scale back to [0, 1] for plotting (since model output is [-1, 1])\n    fake_samples = (img.clamp(-1, 1) + 1) / 2\n    real_samples = (real_samples + 1) / 2 # Assuming dataset output was also [-1, 1]\n\n    # --- C. Plot Comparison ---\n    fig, axes = plt.subplots(2, num_samples, figsize=(3*num_samples, 6))\n    \n    for i in range(num_samples):\n        # Plot Real\n        axes[0, i].imshow(real_samples[i].cpu().squeeze(), cmap='binary')\n        axes[0, i].axis('off')\n        if i == 0: axes[0, i].set_title(\"Real Data (Ground Truth)\", fontsize=14, pad=10)\n        \n        # Plot Generated\n        axes[1, i].imshow(fake_samples[i].cpu().squeeze(), cmap='binary')\n        axes[1, i].axis('off')\n        if i == 0: axes[1, i].set_title(\"Generated (Diffusion)\", fontsize=14, pad=10)\n        \n    plt.tight_layout()\n    plt.show()\n    model.train()\n\n# 3. Run Comparison\ngenerate_and_compare(model, dataset, num_samples=5, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T17:11:47.011055Z","iopub.execute_input":"2026-02-10T17:11:47.011831Z","iopub.status.idle":"2026-02-10T17:11:58.39252Z","shell.execute_reply.started":"2026-02-10T17:11:47.011799Z","shell.execute_reply":"2026-02-10T17:11:58.391569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}